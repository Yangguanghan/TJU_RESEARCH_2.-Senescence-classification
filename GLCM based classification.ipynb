{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41cd451",
   "metadata": {},
   "source": [
    "This script extracts Gray-Level Co-occurrence Matrix (GLCM) texture features from paired diffraction images (P and S polarization) of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "GLCM Feature Extraction + Multi-Classifier Evaluation (SVM OvR & Random Forest)\n",
    "Description: This script extracts GLCM features from paired P/S diffraction images, \n",
    "saves the features to CSV, and evaluates multiple classifiers (SVM with linear, poly, sigmoid, rbf kernels, and Random Forest)\n",
    "using train/validation/test split, cross-validation, confusion matrices, and pairwise accuracy matrices.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tifffile\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "data_dirs = {\n",
    "    \"Healthy\":   r\"E:\\0. Research\\1. Paper_data\\2. Hacat cisplatin ROS\\数据集\\原始数据\\downsample-healthy\",\n",
    "    \"Cisplatin\": r\"E:\\0. Research\\1. Paper_data\\2. Hacat cisplatin ROS\\数据集\\原始数据\\Cisplatin\",\n",
    "    \"H2O2\":      r\"E:\\0. Research\\1. Paper_data\\2. Hacat cisplatin ROS\\数据集\\原始数据\\H2O2\"\n",
    "}\n",
    "resize_size = 128\n",
    "num_threads = 8  # Adjust according to CPU cores\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "distances = [1, 2, 4, 8, 16, 32]\n",
    "properties = ['ASM', 'contrast', 'correlation', 'homogeneity', 'dissimilarity', 'energy']\n",
    "\n",
    "# =========================\n",
    "# Helper functions\n",
    "# =========================\n",
    "def get_image_pairs(folder):\n",
    "    \"\"\"Get all P/S image pairs in a folder\"\"\"\n",
    "    p_files = sorted(glob.glob(os.path.join(folder, \"*-P*.tif*\")))\n",
    "    pairs = []\n",
    "    for p_file in p_files:\n",
    "        s_file = p_file.replace(\"-P\", \"-S\")\n",
    "        if os.path.exists(s_file):\n",
    "            pairs.append((p_file, s_file))\n",
    "    return pairs\n",
    "\n",
    "def extract_glcm_features(img):\n",
    "    \"\"\"Extract GLCM features from a single image (normalized to 0~1)\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    glcm = greycomatrix(img_uint8, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "    feats = []\n",
    "    for prop in properties:\n",
    "        feats.extend(greycoprops(glcm, prop).flatten())\n",
    "    return feats  # 144 features\n",
    "\n",
    "def process_pair(pair):\n",
    "    \"\"\"Extract combined GLCM features from a P/S image pair\"\"\"\n",
    "    p_file, s_file, label = pair\n",
    "    try:\n",
    "        p_img = cv2.resize(tifffile.imread(p_file).astype(np.float32)/65535., (resize_size, resize_size))\n",
    "        s_img = cv2.resize(tifffile.imread(s_file).astype(np.float32)/65535., (resize_size, resize_size))\n",
    "        p_feats = extract_glcm_features(p_img)\n",
    "        s_feats = extract_glcm_features(s_img)\n",
    "        return [label] + p_feats + s_feats\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {p_file} / {s_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# Build list of all image pairs\n",
    "# =========================\n",
    "all_pairs = []\n",
    "for label, folder in data_dirs.items():\n",
    "    pairs = get_image_pairs(folder)\n",
    "    print(f\"{label} folder contains {len(pairs)} image pairs\")\n",
    "    all_pairs.extend([(p, s, label) for p, s in pairs])\n",
    "\n",
    "# =========================\n",
    "# Parallel GLCM feature extraction\n",
    "# =========================\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(process_pair, pair) for pair in all_pairs]\n",
    "    for f in tqdm(as_completed(futures), total=len(futures), desc=\"Processing all pairs\"):\n",
    "        res = f.result()\n",
    "        if res is not None:\n",
    "            results.append(res)\n",
    "\n",
    "# =========================\n",
    "# Save features to CSV\n",
    "# =========================\n",
    "columns = ['Label'] + [f'feat_{i}' for i in range(288)]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "df.to_csv('glcm_features_multithread.csv', index=False)\n",
    "print(\"GLCM features saved to glcm_features_multithread.csv\")\n",
    "\n",
    "# =========================\n",
    "# Load GLCM features\n",
    "# =========================\n",
    "df = pd.read_csv('glcm_features_multithread.csv')\n",
    "X = df.drop(\"Label\", axis=1).values\n",
    "y = df[\"Label\"].values\n",
    "class_names = np.unique(y)\n",
    "\n",
    "# =========================\n",
    "# Train / Validation / Test Split (8:1:1)\n",
    "# =========================\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1111, stratify=y_trainval, random_state=42\n",
    ")  # ~8:1:1\n",
    "print(f\"Train: {len(y_train)}, Validation: {len(y_val)}, Test: {len(y_test)}\")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# Visualization functions\n",
    "# =========================\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_pairwise_accuracy(y_true, y_pred, classes, title=\"Pairwise Accuracy Matrix\"):\n",
    "    n_classes = len(classes)\n",
    "    pairwise_acc = np.zeros((n_classes, n_classes))\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            if i == j:\n",
    "                pairwise_acc[i, j] = 1.0\n",
    "            elif i < j:\n",
    "                mask = np.isin(y_true, [classes[i], classes[j]])\n",
    "                if np.sum(mask) > 0:\n",
    "                    acc = np.mean(y_true[mask] == y_pred[mask])\n",
    "                    pairwise_acc[i, j] = pairwise_acc[j, i] = acc\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(pairwise_acc, annot=True, fmt=\".4f\", xticklabels=classes, yticklabels=classes, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# =========================\n",
    "# Define classifiers\n",
    "# =========================\n",
    "models = {\n",
    "    \"SVM-linear-OvR\": SVC(kernel=\"linear\", probability=True, random_state=42,\n",
    "                          decision_function_shape='ovr'),\n",
    "    \"SVM-poly-OvR\":   SVC(kernel=\"poly\", degree=3, probability=True, random_state=42,\n",
    "                          decision_function_shape='ovr'),\n",
    "    \"SVM-sigmoid-OvR\":SVC(kernel=\"sigmoid\", probability=True, random_state=42,\n",
    "                          decision_function_shape='ovr'),\n",
    "    \"SVM-rbf-OvR\":    SVC(kernel=\"rbf\", probability=True, random_state=42,\n",
    "                          decision_function_shape='ovr'),\n",
    "    \"RandomForest\":   RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Training and Evaluation\n",
    "# =========================\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    \n",
    "    # Cross-validation on train+validation\n",
    "    y_pred_cv = cross_val_predict(model, np.vstack([X_train, X_val]), np.hstack([y_train, y_val]), cv=skf)\n",
    "    print(\"Cross-validation classification report:\")\n",
    "    print(classification_report(np.hstack([y_train, y_val]), y_pred_cv, target_names=class_names, digits=4))\n",
    "    \n",
    "    # Train on train+validation, then evaluate on test\n",
    "    model.fit(np.vstack([X_train, X_val]), np.hstack([y_train, y_val]))\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(\"Test classification report:\")\n",
    "    print(classification_report(y_test, y_pred_test, target_names=class_names, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred_test, class_names, title=f\"{name} - Confusion Matrix (Test)\")\n",
    "    \n",
    "    # Pairwise accuracy\n",
    "    plot_pairwise_accuracy(y_test, y_pred_test, class_names, title=f\"{name} - Pairwise Accuracy Matrix (Test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f0da0",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "SVM-Linear C Parameter Grid Search on GLCM Features\n",
    "Description: This script performs a grid search to find the optimal C parameter for a linear SVM\n",
    "using GLCM features, evaluates on a test set, and plots confusion and pairwise accuracy matrices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1929ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# =========================\n",
    "# Load GLCM features\n",
    "# =========================\n",
    "df = pd.read_csv(\"glcm_merged_normalized_multithread.csv\")\n",
    "X = df.drop(\"Label\", axis=1).values\n",
    "y = df[\"Label\"].values\n",
    "class_names = np.unique(y)\n",
    "\n",
    "# =========================\n",
    "# Train / Validation / Test Split (8:1:1)\n",
    "# =========================\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1111, stratify=y_trainval, random_state=42\n",
    ")  # ~8:1:1\n",
    "\n",
    "print(f\"Train: {len(y_train)}, Validation: {len(y_val)}, Test: {len(y_test)}\")\n",
    "\n",
    "# =========================\n",
    "# Standardization\n",
    "# =========================\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "X_trainval_scaled = np.vstack([X_train, X_val])\n",
    "y_trainval = np.hstack([y_train, y_val])\n",
    "\n",
    "# =========================\n",
    "# Confusion Matrix Plotting\n",
    "# =========================\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n",
    "\n",
    "# =========================\n",
    "# Pairwise Accuracy Plotting\n",
    "# =========================\n",
    "def plot_pairwise_accuracy(y_true, y_pred, classes, title=\"Pairwise Accuracy Matrix\"):\n",
    "    n_classes = len(classes)\n",
    "    pairwise_acc = np.zeros((n_classes, n_classes))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            if i == j:\n",
    "                pairwise_acc[i, j] = 1.0\n",
    "            elif i < j:\n",
    "                mask = np.isin(y_true, [classes[i], classes[j]])\n",
    "                if np.sum(mask) > 0:\n",
    "                    acc = np.mean(y_true[mask] == y_pred[mask])\n",
    "                    pairwise_acc[i, j] = pairwise_acc[j, i] = acc\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(pairwise_acc, annot=True, fmt=\".4f\", xticklabels=classes, yticklabels=classes, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# =========================\n",
    "# Grid Search for Optimal C (Linear SVM)\n",
    "# =========================\n",
    "C_values = list(range(1, 252, 10))  # C = 1, 11, ..., 241\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "mean_accuracies = []\n",
    "for C in C_values:\n",
    "    model = SVC(kernel=\"linear\", C=C, random_state=42)\n",
    "    scores = cross_val_score(model, X_trainval_scaled, y_trainval, cv=cv, scoring=\"accuracy\")\n",
    "    mean_accuracies.append(scores.mean())\n",
    "\n",
    "# Find the best C\n",
    "best_idx = np.argmax(mean_accuracies)\n",
    "best_C = C_values[best_idx]\n",
    "best_acc = mean_accuracies[best_idx]\n",
    "\n",
    "print(f\"Optimal C = {best_C}, Cross-Validation Accuracy = {best_acc:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# Plot Accuracy vs C\n",
    "# =========================\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(C_values, mean_accuracies, marker=\"o\")\n",
    "plt.axvline(best_C, color=\"red\", linestyle=\"--\", label=f\"Best C={best_C}\")\n",
    "plt.xlabel(\"C value\")\n",
    "plt.ylabel(\"Cross-Validation Accuracy\")\n",
    "plt.title(\"SVM (linear) - Accuracy vs C\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Train on Full Train+Val with Best C and Evaluate on Test\n",
    "# =========================\n",
    "final_model = SVC(kernel=\"linear\", C=best_C, probability=True, random_state=42)\n",
    "final_model.fit(X_trainval_scaled, y_trainval)\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion_matrix(y_test, y_pred_test, class_names, title=f\"SVM (linear, C={best_C}) - Confusion Matrix (Test)\")\n",
    "\n",
    "# Pairwise Accuracy Matrix\n",
    "plot_pairwise_accuracy(y_test, y_pred_test, class_names, title=f\"SVM (linear, C={best_C}) - Pairwise Accuracy Matrix (Test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benchmarking GLCM + SVM Inference Time on Test Set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tifffile\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "CSV_PATH = r\"glcm_merged_normalized_multithread.csv\"\n",
    "resize_size = 128\n",
    "\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "distances = [1, 2, 4, 8, 16, 32]\n",
    "properties = ['ASM', 'contrast', 'correlation', 'homogeneity', 'dissimilarity', 'energy']\n",
    "\n",
    "# =========================\n",
    "# Load CSV with features and image paths\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "labels = df[\"Label\"].values\n",
    "p_paths = df[\"P_Path\"].values\n",
    "s_paths = df[\"S_Path\"].values\n",
    "features = df.drop([\"Label\", \"P_Path\", \"S_Path\"], axis=1).values\n",
    "\n",
    "# =========================\n",
    "# Split Train/Validation/Test sets (test only used here)\n",
    "# =========================\n",
    "X_trainval, X_test, y_trainval, y_test, p_trainval, p_test, s_trainval, s_test = train_test_split(\n",
    "    features, labels, p_paths, s_paths,\n",
    "    test_size=0.1, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Standardize + Train SVM with best C\n",
    "# =========================\n",
    "scaler = StandardScaler()\n",
    "X_trainval_scaled = scaler.fit_transform(X_trainval)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "best_C = 21  \n",
    "svm_model = SVC(kernel=\"linear\", C=best_C, probability=False)\n",
    "svm_model.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "# =========================\n",
    "# Define GLCM extraction function\n",
    "# =========================\n",
    "def extract_glcm_features(img):\n",
    "    \"\"\"Extract GLCM features from a single image (normalized to 0-1)\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    glcm = greycomatrix(img_uint8, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "    feats = []\n",
    "    for prop in properties:\n",
    "        feats.extend(greycoprops(glcm, prop).flatten())\n",
    "    return feats\n",
    "\n",
    "# =========================\n",
    "# Benchmarking inference on test set\n",
    "# =========================\n",
    "glcm_times = []\n",
    "svm_times = []\n",
    "full_times = []\n",
    "\n",
    "for p, s, label in tqdm(zip(p_test, s_test, y_test), total=len(y_test), desc=\"Benchmarking Test Set\"):\n",
    "\n",
    "    # Read and resize images\n",
    "    img_p = cv2.resize(tifffile.imread(p).astype(np.float32)/65535., (resize_size, resize_size))\n",
    "    img_s = cv2.resize(tifffile.imread(s).astype(np.float32)/65535., (resize_size, resize_size))\n",
    "\n",
    "    # Time GLCM extraction\n",
    "    t1 = time.perf_counter()\n",
    "    p_feats = extract_glcm_features(img_p)\n",
    "    s_feats = extract_glcm_features(img_s)\n",
    "    feats = np.array(p_feats + s_feats).reshape(1, -1)\n",
    "    t2 = time.perf_counter()\n",
    "    glcm_times.append((t2 - t1) * 1000)  # ms\n",
    "\n",
    "    # Standardize features\n",
    "    feats_scaled = scaler.transform(feats)\n",
    "\n",
    "    # Time SVM prediction\n",
    "    t3 = time.perf_counter()\n",
    "    _ = svm_model.predict(feats_scaled)\n",
    "    t4 = time.perf_counter()\n",
    "    svm_times.append((t4 - t3) * 1000)  # ms\n",
    "\n",
    "    # Full pipeline time\n",
    "    full_times.append((t4 - t1) * 1000)  # ms\n",
    "\n",
    "# =========================\n",
    "# Output benchmarking results\n",
    "# =========================\n",
    "print(\"\\n========== Benchmark Results (Test Set) ==========\")\n",
    "print(f\"[Full Pipeline] GLCM + SVM\")\n",
    "print(f\"  Average: {np.mean(full_times):.3f} ms/sample\")\n",
    "print(f\"  Total: {np.sum(full_times)/1000:.2f} sec for {len(full_times)} samples\\n\")\n",
    "\n",
    "print(f\"[GLCM Only]\")\n",
    "print(f\"  Average: {np.mean(glcm_times):.3f} ms/sample\\n\")\n",
    "\n",
    "print(f\"[SVM Only]\")\n",
    "print(f\"  Average: {np.mean(svm_times)*1000:.3f} µs/sample\")  # convert to microseconds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
